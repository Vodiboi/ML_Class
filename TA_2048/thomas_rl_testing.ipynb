{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b024576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9826810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "# from sb3_contrib.common.maskable.wrappers import VecActionMasker \n",
    "# from sb3_contrib.common.maskable.vec_env import MaskableEnv\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa426f3",
   "metadata": {},
   "source": [
    "# 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b26cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwentyFortyEightEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode='human'):\n",
    "        super().__init__()\n",
    "        self.render_mode = render_mode\n",
    "        self.observation_space = spaces.Box(0, 17, shape=(4, 4), dtype=np.int32)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.grid = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # this lets gymnasium/SB3 seed properly\n",
    "        super().reset(seed=seed)\n",
    "        self.grid = np.zeros((4, 4), dtype=np.int32)\n",
    "        self._add_tile()\n",
    "        self._add_tile()\n",
    "        return self.grid.copy(), {\"action_mask\": self.valid_action_mask()}\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), f\"{action} invalid\"\n",
    "        before = self.grid.copy()\n",
    "        reward = self._move_and_merge(action)\n",
    "        terminated = not self._can_move()\n",
    "        if not np.array_equal(before, self.grid):\n",
    "            self._add_tile()\n",
    "        return self.grid.copy(), reward, terminated, False, {\"action_mask\": self.valid_action_mask()}\n",
    "\n",
    "    def render(self):\n",
    "        grd = (np.where(self.grid != 0, 2**self.grid.astype(np.int32), np.zeros_like(self.grid))).astype(int)\n",
    "        f = lambda x: f\"{x:>3}\" if x != 0 else \"   \"\n",
    "        print(\"-\"*17)\n",
    "        for r in grd:\n",
    "            print(\"|\", end=\"\")\n",
    "            print(*map(f, r), end=\"\")\n",
    "            print(\"|\")\n",
    "        print(\"-\"*17)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def valid_action_mask(self):\n",
    "        # True = valid, False = would do nothing\n",
    "        mask = []\n",
    "        for a in range(self.action_space.n):\n",
    "            # simulate=True returns reward but *doesnâ€™t* modify self.grid\n",
    "            moved = self._move_and_merge(a, simulate=True) > 0\n",
    "            mask.append(moved)\n",
    "        return np.array(mask, dtype=bool)\n",
    "\n",
    "    def _add_tile(self):\n",
    "        empties = list(zip(*np.where(self.grid == 0)))\n",
    "        if not empties: return\n",
    "        y, x = random.choice(empties)\n",
    "        self.grid[y, x] = 1 if random.random() < 0.9 else 2\n",
    "\n",
    "    def _can_move(self):\n",
    "        if np.any(self.grid == 0):\n",
    "            return True\n",
    "        for a in range(4):\n",
    "            if self._move_and_merge(a, simulate=True) > 0:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _move_and_merge(self, action, simulate=False):\n",
    "        grid = self.grid.copy() if simulate else self.grid\n",
    "        orig = self.grid.copy()\n",
    "        total_reward = 0\n",
    "        for i in range(4):\n",
    "            line = grid[:, i] if action < 2 else grid[i, :]\n",
    "            if action % 2 == 1:\n",
    "                line = line[::-1]\n",
    "            nonzero = line[line > 0]\n",
    "            merged, skip = [], False\n",
    "            for j in range(len(nonzero)):\n",
    "                if skip:\n",
    "                    skip = False\n",
    "                    continue\n",
    "                if j+1 < len(nonzero) and nonzero[j] == nonzero[j+1]:\n",
    "                    new_val = nonzero[j] + 1\n",
    "                    merged.append(new_val)\n",
    "                    total_reward += 2**new_val\n",
    "                    skip = True\n",
    "                else:\n",
    "                    merged.append(nonzero[j])\n",
    "            merged = np.array(merged + [0]*(4-len(merged)), dtype=np.int32)\n",
    "            if action % 2 == 1:\n",
    "                merged = merged[::-1]\n",
    "            if action < 2:\n",
    "                grid[:, i] = merged\n",
    "            else:\n",
    "                grid[i, :] = merged\n",
    "        # add in something to really incentivize not doing nothing\n",
    "        if (grid == orig).all():\n",
    "            total_reward = -2.0\n",
    "        if not simulate:\n",
    "            self.grid = grid\n",
    "        return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d99488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb85c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: mps\n",
      "Using mps device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasdellavigna/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n",
      "/Users/thomasdellavigna/Library/Python/3.9/lib/python/site-packages/torch/nn/init.py:610: UserWarning: The operator 'aten::linalg_qr.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:14.)\n",
      "  q, r = torch.linalg.qr(flattened)\n",
      "/Users/thomasdellavigna/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 99   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 20   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Current device: {device}\")\n",
    "\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 160):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        self.dep =30\n",
    "\n",
    "        self.embed= nn.Embedding(20,self.dep)\n",
    "        self.posEm= nn.Embedding(16,self.dep)\n",
    "        self.cnn1 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm([self.dep,4,4]) )\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm([self.dep,4,4]) )\n",
    "        self.cnn3 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.dep, self.dep, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm([self.dep,4,4]))\n",
    "\n",
    "        self.cnn4 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(self.dep, self.dep//4*3, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.dep//4*3, self.dep//2, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.dep//2, self.dep//4, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm([self.dep//4,4,4]),\n",
    "            nn.Flatten(start_dim=1))\n",
    "\n",
    "        n_flatten = self.dep//4*16\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(n_flatten, 32*2), nn.ReLU(),\n",
    "            # nn.Linear(50, 50), nn.ReLU(),\n",
    "            nn.Linear(32*2, features_dim), nn.ReLU(),\n",
    "            )\n",
    "        self.to(device=device)\n",
    "    def do_cnn(self, input_1):\n",
    "        res=self.cnn1(input_1)+input_1\n",
    "        res=self.cnn2(res)+res\n",
    "        return self.cnn4(self.cnn3(res)+res)\n",
    "\n",
    "    def do_embed(self, observations):\n",
    "        observations=observations.to(device=device)\n",
    "        add_pos=self.posEm(torch.tensor([i for i in range(16)], dtype=torch.int,device=device)).reshape((4,4,self.dep))\n",
    "        obs=observations.type(torch.int)\n",
    "        return(self.embed(obs)+add_pos).reshape((observations.shape[0],self.dep,4,4))\n",
    "\n",
    "\n",
    "    def forward(self, observations) -> torch.Tensor:\n",
    "        embed= self.do_embed(observations)\n",
    "        final1=self.linear(self.do_cnn(embed))\n",
    "        # final2= self.linear(self.cnn( torch.rot90( embed,1,[2,3])))\n",
    "        # final3= self.linear(self.cnn( torch.rot90( embed,2,[2,3])))\n",
    "        # final4= self.linear(self.cnn( torch.rot90( embed,3,[2,3])))\n",
    "\n",
    "        # print(torch.concat( (final1,final2,final3,final4)).shape,\"Hi\",final1.shape)\n",
    "        # return torch.concat( (final1,final2,final3,final4),dim=1)\n",
    "        return final1\n",
    "\n",
    "# 1) sanity-check env\n",
    "\n",
    "# 2) vectorize\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=64),\n",
    "    net_arch=[64, 64]\n",
    ")\n",
    "\n",
    "base_env = TwentyFortyEightEnv()\n",
    "check_env(base_env, warn=True)                # <-- will raise if your env is non-compliant\n",
    "\n",
    "def make_env():\n",
    "    env = TwentyFortyEightEnv(render_mode='human')\n",
    "    return env\n",
    "\n",
    "vec_env = DummyVecEnv([make_env])\n",
    "model = PPO(\"MlpPolicy\", vec_env, policy_kwargs=policy_kwargs, verbose=1, n_epochs=100, batch_size=256, device=device)\n",
    "\n",
    "model.learn(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c98afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model/jun/2.1.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5082cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.learn(100000)\n",
    "# model.save(\"best_model/jun/2.2.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed171969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# print(os.getenv(\"PYTORCH_ENABLE_MPS_FALLBACK\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc27bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasdellavigna/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1) sanity-check env\n",
    "base_env = TwentyFortyEightEnv()\n",
    "check_env(base_env, warn=True)                # <-- will raise if your env is non-compliant\n",
    "\n",
    "def make_env():\n",
    "    env = TwentyFortyEightEnv(render_mode='human')\n",
    "    return env\n",
    "def make_env_play():\n",
    "    env = TwentyFortyEightEnv_play(render_mode='human')\n",
    "    return env\n",
    "# 2) vectorize\n",
    "# vec_env = DummyVecEnv([make_env])\n",
    "\n",
    "vec_env_play = DummyVecEnv([make_env_play])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d6787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aayanarish/Library/Python/3.10/lib/python/site-packages/stable_baselines3/common/env_checker.py:272: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Policy MlpLstmPolicy unknown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m vec_env \u001b[38;5;241m=\u001b[39m DummyVecEnv([make_env])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 3) train with any SB3 algo\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMlpLstmPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvec_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 500_000 with default lr gives a score 300 smth\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200_000\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/stable_baselines3/ppo/ppo.py:109\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     82\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[ActorCriticPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    108\u001b[0m ):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgae_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgae_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43ment_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ment_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvf_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvf_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrollout_buffer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrollout_buffer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrollout_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrollout_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_init_setup_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDiscrete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiBinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# Sanity check, otherwise it will lead to noisy gradient and NaN\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# because of the advantage normalization\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m normalize_advantage:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/stable_baselines3/common/on_policy_algorithm.py:86\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, stats_window_size, tensorboard_log, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     63\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[ActorCriticPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     supported_action_spaces: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtype\u001b[39m[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     85\u001b[0m ):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps \u001b[38;5;241m=\u001b[39m n_steps\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m=\u001b[39m gamma\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/stable_baselines3/common/base_class.py:124\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    108\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[BasePolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     supported_action_spaces: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtype\u001b[39m[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(policy, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_policy_from_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class \u001b[38;5;241m=\u001b[39m policy\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/stable_baselines3/common/base_class.py:339\u001b[0m, in \u001b[0;36mBaseAlgorithm._get_policy_from_name\u001b[0;34m(self, policy_name)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_aliases[policy_name]\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpolicy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Policy MlpLstmPolicy unknown"
     ]
    }
   ],
   "source": [
    "#rtain\n",
    "model = PPO(\"MlpLstmPolicy\", vec_env, verbose=1, n_epochs=30, learning_rate=5e-3)\n",
    "# 500_000 with default lr gives a score 300 smth\n",
    "model.learn(total_timesteps=200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31bc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/tjrmvbjx24dcxfzdxg41rr400000gp/T/ipykernel_77553/2153850915.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs=torch.tensor(observations, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move 1: left, reward: 4, total reward: 4\n",
      "-----------------\n",
      "|          2    |\n",
      "|               |\n",
      "|  4            |\n",
      "|               |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 2: down, reward: 0, total reward: 4\n",
      "-----------------\n",
      "|               |\n",
      "|          2    |\n",
      "|               |\n",
      "|  4       2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 3: down, reward: 4, total reward: 8\n",
      "-----------------\n",
      "|               |\n",
      "|               |\n",
      "|  2            |\n",
      "|  4       4    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 4: left, reward: 8, total reward: 16\n",
      "-----------------\n",
      "|  2            |\n",
      "|               |\n",
      "|  2            |\n",
      "|  8            |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 5: left, reward: 0, total reward: 16\n",
      "-----------------\n",
      "|  2            |\n",
      "|               |\n",
      "|  2            |\n",
      "|  8            |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 6: left, reward: 0, total reward: 16\n",
      "-----------------\n",
      "|  2            |\n",
      "|               |\n",
      "|  2            |\n",
      "|  8            |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 7: right, reward: 0, total reward: 16\n",
      "-----------------\n",
      "|              2|\n",
      "|      4        |\n",
      "|              2|\n",
      "|              8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 8: down, reward: 4, total reward: 20\n",
      "-----------------\n",
      "|               |\n",
      "|               |\n",
      "|  2           4|\n",
      "|      4       8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 9: left, reward: 0, total reward: 20\n",
      "-----------------\n",
      "|              2|\n",
      "|               |\n",
      "|  2   4        |\n",
      "|  4   8        |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 10: right, reward: 0, total reward: 20\n",
      "-----------------\n",
      "|  2           2|\n",
      "|               |\n",
      "|          2   4|\n",
      "|          4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 11: left, reward: 4, total reward: 24\n",
      "-----------------\n",
      "|  4            |\n",
      "|  2            |\n",
      "|  2   4        |\n",
      "|  4   8        |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 12: right, reward: 0, total reward: 24\n",
      "-----------------\n",
      "|              4|\n",
      "|              2|\n",
      "|  4       2   4|\n",
      "|          4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 13: left, reward: 0, total reward: 24\n",
      "-----------------\n",
      "|  4       2    |\n",
      "|  2            |\n",
      "|  4   2   4    |\n",
      "|  4   8        |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 14: right, reward: 0, total reward: 24\n",
      "-----------------\n",
      "|          4   2|\n",
      "|          4   2|\n",
      "|      4   2   4|\n",
      "|          4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 15: down, reward: 12, total reward: 36\n",
      "-----------------\n",
      "|               |\n",
      "|  2       8   4|\n",
      "|          2   4|\n",
      "|      4   4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 16: up, reward: 8, total reward: 44\n",
      "-----------------\n",
      "|  2   4   8   8|\n",
      "|          2   8|\n",
      "|          4    |\n",
      "|          2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 17: down, reward: 16, total reward: 60\n",
      "-----------------\n",
      "|          8    |\n",
      "|          2    |\n",
      "|      2   4    |\n",
      "|  2   4   2  16|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 18: up, reward: 0, total reward: 60\n",
      "-----------------\n",
      "|  2   2   8  16|\n",
      "|      4   2    |\n",
      "|      4   4    |\n",
      "|          2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 19: up, reward: 8, total reward: 68\n",
      "-----------------\n",
      "|  2   2   8  16|\n",
      "|      8   2    |\n",
      "|  2       4    |\n",
      "|          2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 20: left, reward: 4, total reward: 72\n",
      "-----------------\n",
      "|  4   8  16    |\n",
      "|  8   2   2    |\n",
      "|  2   4        |\n",
      "|  2            |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 21: down, reward: 4, total reward: 76\n",
      "-----------------\n",
      "|               |\n",
      "|  4   8       2|\n",
      "|  8   2  16    |\n",
      "|  4   4   2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 22: down, reward: 0, total reward: 76\n",
      "-----------------\n",
      "|          2    |\n",
      "|  4   8        |\n",
      "|  8   2  16    |\n",
      "|  4   4   2   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 23: down, reward: 0, total reward: 76\n",
      "-----------------\n",
      "|               |\n",
      "|  4   8   2    |\n",
      "|  8   2  16   2|\n",
      "|  4   4   2   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 24: left, reward: 12, total reward: 88\n",
      "-----------------\n",
      "|               |\n",
      "|  4   8   2    |\n",
      "|  8   2  16   2|\n",
      "|  8   4   2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 25: right, reward: 0, total reward: 88\n",
      "-----------------\n",
      "|  2            |\n",
      "|      4   8   2|\n",
      "|  8   2  16   2|\n",
      "|      8   4   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 26: down, reward: 4, total reward: 92\n",
      "-----------------\n",
      "|              2|\n",
      "|      4   8    |\n",
      "|  2   2  16   2|\n",
      "|  8   8   4   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 27: up, reward: 4, total reward: 96\n",
      "-----------------\n",
      "|  2   4   8   4|\n",
      "|  8   2  16   4|\n",
      "|      8   4    |\n",
      "|              2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 28: right, reward: 0, total reward: 96\n",
      "-----------------\n",
      "|  2   4   8   4|\n",
      "|  8   2  16   4|\n",
      "|          8   4|\n",
      "|      2       2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 29: left, reward: 4, total reward: 100\n",
      "-----------------\n",
      "|  2   4   8   4|\n",
      "|  8   2  16   4|\n",
      "|  8   4        |\n",
      "|  4           2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 30: up, reward: 24, total reward: 124\n",
      "-----------------\n",
      "|  2   4   8   8|\n",
      "| 16   2  16   2|\n",
      "|  4   4        |\n",
      "|          2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 31: left, reward: 24, total reward: 148\n",
      "-----------------\n",
      "|  2   4  16    |\n",
      "| 16   2  16   2|\n",
      "|  8            |\n",
      "|  2       2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 32: right, reward: 4, total reward: 152\n",
      "-----------------\n",
      "|  2   2   4  16|\n",
      "| 16   2  16   2|\n",
      "|              8|\n",
      "|              4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 33: down, reward: 4, total reward: 156\n",
      "-----------------\n",
      "|             16|\n",
      "|      2       2|\n",
      "|  2       4   8|\n",
      "| 16   4  16   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 34: right, reward: 4, total reward: 160\n",
      "-----------------\n",
      "|          2  16|\n",
      "|              4|\n",
      "|      2   4   8|\n",
      "| 16   4  16   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 35: left, reward: 0, total reward: 160\n",
      "-----------------\n",
      "|  2  16   2    |\n",
      "|  4            |\n",
      "|  2   4   8    |\n",
      "| 16   4  16   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 36: right, reward: 0, total reward: 160\n",
      "-----------------\n",
      "|      2  16   2|\n",
      "|      2       4|\n",
      "|      2   4   8|\n",
      "| 16   4  16   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 37: left, reward: 0, total reward: 160\n",
      "-----------------\n",
      "|  2  16   2    |\n",
      "|  2   4        |\n",
      "|  2   4   8   2|\n",
      "| 16   4  16   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 38: up, reward: 12, total reward: 172\n",
      "-----------------\n",
      "|  4  16   2   2|\n",
      "|  2   8   8   4|\n",
      "| 16   4  16    |\n",
      "|              2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 39: right, reward: 20, total reward: 192\n",
      "-----------------\n",
      "|      4  16   4|\n",
      "|      2  16   4|\n",
      "|     16   4  16|\n",
      "|      2       2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 40: down, reward: 40, total reward: 232\n",
      "-----------------\n",
      "|      4       2|\n",
      "|      2       8|\n",
      "|     16  32  16|\n",
      "|      2   4   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 41: left, reward: 0, total reward: 232\n",
      "-----------------\n",
      "|  4   2        |\n",
      "|  2   8        |\n",
      "| 16  32  16    |\n",
      "|  2   4   2   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 42: right, reward: 4, total reward: 236\n",
      "-----------------\n",
      "|          4   2|\n",
      "|      2   2   8|\n",
      "|     16  32  16|\n",
      "|      2   4   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 43: left, reward: 12, total reward: 248\n",
      "-----------------\n",
      "|  4   2   2    |\n",
      "|  4   8        |\n",
      "| 16  32  16    |\n",
      "|  2   8        |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 44: right, reward: 4, total reward: 252\n",
      "-----------------\n",
      "|  2       4   4|\n",
      "|          4   8|\n",
      "|     16  32  16|\n",
      "|          2   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 45: left, reward: 8, total reward: 260\n",
      "-----------------\n",
      "|  2   8        |\n",
      "|  4   8        |\n",
      "| 16  32  16   2|\n",
      "|  2   8        |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 46: up, reward: 16, total reward: 276\n",
      "-----------------\n",
      "|  2  16  16   2|\n",
      "|  4  32        |\n",
      "| 16   8   2    |\n",
      "|  2            |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 47: right, reward: 32, total reward: 308\n",
      "-----------------\n",
      "|  2   2  32   2|\n",
      "|          4  32|\n",
      "|     16   8   2|\n",
      "|              2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 48: up, reward: 4, total reward: 312\n",
      "-----------------\n",
      "|  2   2  32   2|\n",
      "|  2  16   4  32|\n",
      "|          8   4|\n",
      "|               |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 49: down, reward: 4, total reward: 316\n",
      "-----------------\n",
      "|               |\n",
      "|         32   2|\n",
      "|  2   2   4  32|\n",
      "|  4  16   8   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 50: down, reward: 0, total reward: 316\n",
      "-----------------\n",
      "|               |\n",
      "|         32   2|\n",
      "|  2   2   4  32|\n",
      "|  4  16   8   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 51: up, reward: 0, total reward: 316\n",
      "-----------------\n",
      "|  2   2  32   2|\n",
      "|  4  16   4  32|\n",
      "|          8   4|\n",
      "|  2            |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 52: left, reward: 4, total reward: 320\n",
      "-----------------\n",
      "|  4  32   2    |\n",
      "|  4  16   4  32|\n",
      "|  8   4        |\n",
      "|  2       2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 53: left, reward: 4, total reward: 324\n",
      "-----------------\n",
      "|  4  32   2    |\n",
      "|  4  16   4  32|\n",
      "|  8   4   2    |\n",
      "|  4            |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 54: down, reward: 8, total reward: 332\n",
      "-----------------\n",
      "|              2|\n",
      "|  8  32   2    |\n",
      "|  8  16   4    |\n",
      "|  4   4   2  32|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 55: down, reward: 16, total reward: 348\n",
      "-----------------\n",
      "|               |\n",
      "|     32   2   2|\n",
      "| 16  16   4   2|\n",
      "|  4   4   2  32|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 56: left, reward: 44, total reward: 392\n",
      "-----------------\n",
      "|              2|\n",
      "| 32   4        |\n",
      "| 32   4   2    |\n",
      "|  8   2  32    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 57: down, reward: 72, total reward: 464\n",
      "-----------------\n",
      "|      2        |\n",
      "|               |\n",
      "| 64   8   2    |\n",
      "|  8   2  32   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 58: left, reward: 0, total reward: 464\n",
      "-----------------\n",
      "|  2            |\n",
      "|  2            |\n",
      "| 64   8   2    |\n",
      "|  8   2  32   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 59: right, reward: 0, total reward: 464\n",
      "-----------------\n",
      "|              2|\n",
      "|  2           2|\n",
      "|     64   8   2|\n",
      "|  8   2  32   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 60: right, reward: 4, total reward: 468\n",
      "-----------------\n",
      "|              2|\n",
      "|          2   4|\n",
      "|     64   8   2|\n",
      "|  8   2  32   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 61: right, reward: 0, total reward: 468\n",
      "-----------------\n",
      "|              2|\n",
      "|          2   4|\n",
      "|     64   8   2|\n",
      "|  8   2  32   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 62: down, reward: 4, total reward: 472\n",
      "-----------------\n",
      "|               |\n",
      "|          2   2|\n",
      "|  2  64   8   4|\n",
      "|  8   2  32   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 63: down, reward: 8, total reward: 480\n",
      "-----------------\n",
      "|               |\n",
      "|          2   2|\n",
      "|  2  64   8   2|\n",
      "|  8   2  32   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 64: down, reward: 4, total reward: 484\n",
      "-----------------\n",
      "|  2            |\n",
      "|          2    |\n",
      "|  2  64   8   4|\n",
      "|  8   2  32   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 65: left, reward: 0, total reward: 484\n",
      "-----------------\n",
      "|  2            |\n",
      "|  2           2|\n",
      "|  2  64   8   4|\n",
      "|  8   2  32   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 66: down, reward: 4, total reward: 488\n",
      "-----------------\n",
      "|               |\n",
      "|  2   4       2|\n",
      "|  4  64   8   4|\n",
      "|  8   2  32   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 67: up, reward: 0, total reward: 488\n",
      "-----------------\n",
      "|  2   4   8   2|\n",
      "|  4  64  32   4|\n",
      "|  8   2       8|\n",
      "|              4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 68: right, reward: 0, total reward: 488\n",
      "-----------------\n",
      "|  2   4   8   2|\n",
      "|  4  64  32   4|\n",
      "|      8   2   8|\n",
      "|  2           4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 69: up, reward: 0, total reward: 488\n",
      "-----------------\n",
      "|  2   4   8   2|\n",
      "|  4  64  32   4|\n",
      "|  2   8   2   8|\n",
      "|      2       4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 70: left, reward: 0, total reward: 488\n",
      "-----------------\n",
      "|  2   4   8   2|\n",
      "|  4  64  32   4|\n",
      "|  2   8   2   8|\n",
      "|  2   4   2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 71: down, reward: 8, total reward: 496\n",
      "-----------------\n",
      "|      4   4    |\n",
      "|  2  64   8   2|\n",
      "|  4   8  32   4|\n",
      "|  4   4   4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 72: down, reward: 8, total reward: 504\n",
      "-----------------\n",
      "|  2   4   4    |\n",
      "|     64   8   2|\n",
      "|  2   8  32   4|\n",
      "|  8   4   4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 73: up, reward: 4, total reward: 508\n",
      "-----------------\n",
      "|  4   4   4   2|\n",
      "|  8  64   8   4|\n",
      "|  2   8  32   8|\n",
      "|      4   4    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 74: up, reward: 0, total reward: 508\n",
      "-----------------\n",
      "|  4   4   4   2|\n",
      "|  8  64   8   4|\n",
      "|  2   8  32   8|\n",
      "|      4   4    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 75: down, reward: 0, total reward: 508\n",
      "-----------------\n",
      "|  2   4   4    |\n",
      "|  4  64   8   2|\n",
      "|  8   8  32   4|\n",
      "|  2   4   4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 76: up, reward: 0, total reward: 508\n",
      "-----------------\n",
      "|  2   4   4   2|\n",
      "|  4  64   8   4|\n",
      "|  8   8  32   8|\n",
      "|  2   4   4   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 77: left, reward: 32, total reward: 540\n",
      "-----------------\n",
      "|  2   8   2    |\n",
      "|  4  64   8   4|\n",
      "| 16  32   8    |\n",
      "|  2   8   2   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 78: up, reward: 16, total reward: 556\n",
      "-----------------\n",
      "|  2   8   2   4|\n",
      "|  4  64  16   2|\n",
      "| 16  32   2    |\n",
      "|  2   8       2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 79: left, reward: 0, total reward: 556\n",
      "-----------------\n",
      "|  2   8   2   4|\n",
      "|  4  64  16   2|\n",
      "| 16  32   2    |\n",
      "|  2   8   2   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 80: down, reward: 8, total reward: 564\n",
      "-----------------\n",
      "|  2   8   2    |\n",
      "|  4  64   2    |\n",
      "| 16  32  16   4|\n",
      "|  2   8   4   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 81: left, reward: 8, total reward: 572\n",
      "-----------------\n",
      "|  2   8   2    |\n",
      "|  4  64   2    |\n",
      "| 16  32  16   4|\n",
      "|  2   8   8   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 82: up, reward: 4, total reward: 576\n",
      "-----------------\n",
      "|  2   8   4   4|\n",
      "|  4  64  16   2|\n",
      "| 16  32   8   2|\n",
      "|  2   8        |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 83: up, reward: 4, total reward: 580\n",
      "-----------------\n",
      "|  2   8   4   4|\n",
      "|  4  64  16   4|\n",
      "| 16  32   8   2|\n",
      "|  2   8        |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 84: down, reward: 8, total reward: 588\n",
      "-----------------\n",
      "|  2   8        |\n",
      "|  4  64   4   2|\n",
      "| 16  32  16   8|\n",
      "|  2   8   8   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 85: up, reward: 0, total reward: 588\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  4  64  16   8|\n",
      "| 16  32   8   2|\n",
      "|  2   8       2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 86: down, reward: 4, total reward: 592\n",
      "-----------------\n",
      "|  2   8       4|\n",
      "|  4  64   4   2|\n",
      "| 16  32  16   8|\n",
      "|  2   8   8   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 87: right, reward: 16, total reward: 608\n",
      "-----------------\n",
      "|  2   2   8   4|\n",
      "|  4  64   4   2|\n",
      "| 16  32  16   8|\n",
      "|      2  16   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 88: right, reward: 4, total reward: 612\n",
      "-----------------\n",
      "|      4   8   4|\n",
      "|  4  64   4   2|\n",
      "| 16  32  16   8|\n",
      "|  2   2  16   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 89: left, reward: 4, total reward: 616\n",
      "-----------------\n",
      "|  4   8   4   2|\n",
      "|  4  64   4   2|\n",
      "| 16  32  16   8|\n",
      "|  4  16   4    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 90: down, reward: 20, total reward: 636\n",
      "-----------------\n",
      "|      8       2|\n",
      "|  8  64   8    |\n",
      "| 16  32  16   4|\n",
      "|  4  16   4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 91: left, reward: 0, total reward: 636\n",
      "-----------------\n",
      "|  8   2       4|\n",
      "|  8  64   8    |\n",
      "| 16  32  16   4|\n",
      "|  4  16   4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 92: down, reward: 24, total reward: 660\n",
      "-----------------\n",
      "|  2   2        |\n",
      "| 16  64   8    |\n",
      "| 16  32  16   8|\n",
      "|  4  16   4   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 93: down, reward: 48, total reward: 708\n",
      "-----------------\n",
      "|      2   2    |\n",
      "|  2  64   8    |\n",
      "| 32  32  16    |\n",
      "|  4  16   4  16|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 94: left, reward: 68, total reward: 776\n",
      "-----------------\n",
      "|  4   2        |\n",
      "|  2  64   8    |\n",
      "| 64  16        |\n",
      "|  4  16   4  16|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 95: left, reward: 0, total reward: 776\n",
      "-----------------\n",
      "|  4   2        |\n",
      "|  2  64   8    |\n",
      "| 64  16        |\n",
      "|  4  16   4  16|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 96: up, reward: 32, total reward: 808\n",
      "-----------------\n",
      "|  4   2   8  16|\n",
      "|  2  64   4    |\n",
      "| 64  32        |\n",
      "|  4       2    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 97: down, reward: 0, total reward: 808\n",
      "-----------------\n",
      "|  4   2        |\n",
      "|  2   2   8    |\n",
      "| 64  64   4    |\n",
      "|  4  32   2  16|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 98: up, reward: 4, total reward: 812\n",
      "-----------------\n",
      "|  4   4   8  16|\n",
      "|  2  64   4    |\n",
      "| 64  32   2    |\n",
      "|  4           2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 99: left, reward: 8, total reward: 820\n",
      "-----------------\n",
      "|  8   8  16    |\n",
      "|  2  64   4    |\n",
      "| 64  32   2    |\n",
      "|  4   2       2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 100: right, reward: 20, total reward: 840\n",
      "-----------------\n",
      "|  2      16  16|\n",
      "|      2  64   4|\n",
      "|     64  32   2|\n",
      "|          4   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 101: left, reward: 40, total reward: 880\n",
      "-----------------\n",
      "|  2  32        |\n",
      "|  2  64   4   2|\n",
      "| 64  32   2    |\n",
      "|  8            |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 102: down, reward: 4, total reward: 884\n",
      "-----------------\n",
      "|               |\n",
      "|  4  32   2    |\n",
      "| 64  64   4    |\n",
      "|  8  32   2   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 103: right, reward: 132, total reward: 1016\n",
      "-----------------\n",
      "|               |\n",
      "|      4  32   2|\n",
      "|      2 128   4|\n",
      "|      8  32   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 104: left, reward: 0, total reward: 1016\n",
      "-----------------\n",
      "|          2    |\n",
      "|  4  32   2    |\n",
      "|  2 128   4    |\n",
      "|  8  32   4    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 105: down, reward: 12, total reward: 1028\n",
      "-----------------\n",
      "|      2        |\n",
      "|  4  32        |\n",
      "|  2 128   4    |\n",
      "|  8  32   8    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 106: down, reward: 0, total reward: 1028\n",
      "-----------------\n",
      "|      2        |\n",
      "|  4  32        |\n",
      "|  2 128   4    |\n",
      "|  8  32   8    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 107: up, reward: 0, total reward: 1028\n",
      "-----------------\n",
      "|  4   2   4    |\n",
      "|  2  32   8    |\n",
      "|  8 128       2|\n",
      "|     32        |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 108: left, reward: 0, total reward: 1028\n",
      "-----------------\n",
      "|  4   2   4    |\n",
      "|  2  32   8    |\n",
      "|  8 128   2    |\n",
      "| 32           2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 109: right, reward: 0, total reward: 1028\n",
      "-----------------\n",
      "|      4   2   4|\n",
      "|  2   2  32   8|\n",
      "|      8 128   2|\n",
      "|         32   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 110: down, reward: 4, total reward: 1032\n",
      "-----------------\n",
      "|          2    |\n",
      "|  4   4  32   4|\n",
      "|      2 128   8|\n",
      "|  2   8  32   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 111: down, reward: 0, total reward: 1032\n",
      "-----------------\n",
      "|          2    |\n",
      "|  2   4  32   4|\n",
      "|  4   2 128   8|\n",
      "|  2   8  32   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 112: left, reward: 0, total reward: 1032\n",
      "-----------------\n",
      "|  2       2    |\n",
      "|  2   4  32   4|\n",
      "|  4   2 128   8|\n",
      "|  2   8  32   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 113: down, reward: 4, total reward: 1036\n",
      "-----------------\n",
      "|          2   2|\n",
      "|  4   4  32   4|\n",
      "|  4   2 128   8|\n",
      "|  2   8  32   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 114: left, reward: 12, total reward: 1048\n",
      "-----------------\n",
      "|  4            |\n",
      "|  8  32   4   2|\n",
      "|  4   2 128   8|\n",
      "|  2   8  32   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 115: up, reward: 0, total reward: 1048\n",
      "-----------------\n",
      "|  4  32   4   2|\n",
      "|  8   2 128   8|\n",
      "|  4   8  32   4|\n",
      "|  2       4    |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 116: right, reward: 0, total reward: 1048\n",
      "-----------------\n",
      "|  4  32   4   2|\n",
      "|  8   2 128   8|\n",
      "|  4   8  32   4|\n",
      "|  2       2   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 117: down, reward: 8, total reward: 1056\n",
      "-----------------\n",
      "|  4       4   2|\n",
      "|  8  32 128   2|\n",
      "|  4   2  32   8|\n",
      "|  2   8   2   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 118: left, reward: 8, total reward: 1064\n",
      "-----------------\n",
      "|  8   2   2    |\n",
      "|  8  32 128   2|\n",
      "|  4   2  32   8|\n",
      "|  2   8   2   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 119: right, reward: 4, total reward: 1068\n",
      "-----------------\n",
      "|  2       8   4|\n",
      "|  8  32 128   2|\n",
      "|  4   2  32   8|\n",
      "|  2   8   2   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 120: left, reward: 0, total reward: 1068\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128   2|\n",
      "|  4   2  32   8|\n",
      "|  2   8   2   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 121: left, reward: 0, total reward: 1068\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128   2|\n",
      "|  4   2  32   8|\n",
      "|  2   8   2   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 122: left, reward: 0, total reward: 1068\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128   2|\n",
      "|  4   2  32   8|\n",
      "|  2   8   2   8|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 123: down, reward: 20, total reward: 1088\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128    |\n",
      "|  4   2  32   4|\n",
      "|  2   8   2  16|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 124: left, reward: 0, total reward: 1088\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128    |\n",
      "|  4   2  32   4|\n",
      "|  2   8   2  16|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 125: left, reward: 0, total reward: 1088\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128    |\n",
      "|  4   2  32   4|\n",
      "|  2   8   2  16|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 126: up, reward: 0, total reward: 1088\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128   4|\n",
      "|  4   2  32  16|\n",
      "|  2   8   2   2|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 127: right, reward: 4, total reward: 1092\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128   4|\n",
      "|  4   2  32  16|\n",
      "|  2   2   8   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 128: right, reward: 4, total reward: 1096\n",
      "-----------------\n",
      "|  2   8   4   2|\n",
      "|  8  32 128   4|\n",
      "|  4   2  32  16|\n",
      "|  2   4   8   4|\n",
      "-----------------\n",
      "\n",
      "\n",
      "Move 129: left, reward: 0, total reward: 1096\n",
      "-----------------\n",
      "|          2    |\n",
      "|               |\n",
      "|  2            |\n",
      "|               |\n",
      "-----------------\n",
      "\n",
      "\n",
      "Final score (sum of merges): 1096\n"
     ]
    }
   ],
   "source": [
    "# 4) play one game\n",
    "obs = vec_env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "k = 0\n",
    "dirr = {\n",
    "    0 : \"up\",\n",
    "    1 : \"down\",\n",
    "    2 : \"left\",\n",
    "    3 : \"right\",\n",
    "}\n",
    "env = make_env()\n",
    "# vec_env_play = make_env_play()\n",
    "re=nn.ReLU()\n",
    "while not done:\n",
    "    k += 1\n",
    "    # am = get_action_masks(env)\n",
    "    action, _ = model.predict(obs, deterministic=False)\n",
    "    obs, reward, done, _ = vec_env.step(action)\n",
    "    reward=max(int(reward[0]),0)\n",
    "    total_reward += reward\n",
    "    print(f\"Move {k}: {dirr[action[0]]}, reward: {reward}, total reward: {total_reward}\")\n",
    "    vec_env.render()\n",
    "    # print(action)\n",
    "    time.sleep(0.2)\n",
    "print(\"Final score (sum of merges):\", total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1033.5 1044.0 482.36807 2532.0 256.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/tjrmvbjx24dcxfzdxg41rr400000gp/T/ipykernel_77553/2153850915.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs=torch.tensor(observations, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160.0 1126.0 529.5431993709295 2856.0 316.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_random():\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    k = 0\n",
    "    while not done:\n",
    "        k += 1\n",
    "        # am = get_action_masks(env)\n",
    "        action = [random.randint(0, 3)]\n",
    "        _, reward, done, _ = vec_env.step(action)\n",
    "        total_reward += max(reward[0],0)\n",
    "    return total_reward\n",
    "def do_thing():\n",
    "    obs = vec_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    k = 0\n",
    "    while not done:\n",
    "        k += 1\n",
    "        # am = get_action_masks(env)\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, _ = vec_env.step(action)\n",
    "        total_reward += max(reward[0],0)\n",
    "    return total_reward\n",
    "def do_wfnc(fnc):\n",
    "    l = np.array([fnc() for _ in range(40)])\n",
    "    plt.hist(l, bins=range(int(np.min(l)), int(np.max(l))+1, 2))\n",
    "    print(np.mean(l), np.median(l), np.std(l), np.max(l), np.min(l))\n",
    "do_wfnc(do_random)\n",
    "do_wfnc(do_thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af022152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1178.6 1072.0 570.0718200367389 3168.0 228.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/tjrmvbjx24dcxfzdxg41rr400000gp/T/ipykernel_77553/2153850915.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs=torch.tensor(observations, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1138.32 1072.0 577.67566817376 3092.0 244.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_random():\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    k = 0\n",
    "    while not done:\n",
    "        k += 1\n",
    "        # am = get_action_masks(env)\n",
    "        action = [random.randint(0, 3)]\n",
    "        _, reward, done, _ = vec_env.step(action)\n",
    "        total_reward += max(reward[0],0)\n",
    "    return total_reward\n",
    "def do_thing():\n",
    "    obs = vec_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    k = 0\n",
    "    while not done:\n",
    "        k += 1\n",
    "        # am = get_action_masks(env)\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        obs, reward, done, _ = vec_env.step(action)\n",
    "        total_reward += max(reward[0],0)\n",
    "    return total_reward\n",
    "def do_wfnc(fnc):\n",
    "    l = np.array([fnc() for _ in range(100)])\n",
    "    plt.hist(l, bins=range(int(np.min(l)), int(np.max(l))+1, 2))\n",
    "    print(np.mean(l), np.median(l), np.std(l), np.max(l), np.min(l))\n",
    "do_wfnc(do_random)\n",
    "do_wfnc(do_thing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
